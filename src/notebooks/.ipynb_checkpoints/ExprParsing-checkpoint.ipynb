{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Import/Code Header#"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import HTML\n",
      "toggle_sections = HTML(\"\"\"\n",
      "<script type=\"text/javascript\">\n",
      "     show=true;\n",
      "     function toggle(){\n",
      "         if (show){\n",
      "             $('div.input').hide();\n",
      "             $('div.output_area').hide();\n",
      "             $(\"#toggle\").parent().parent().show()\n",
      "         }else{\n",
      "             $('div.input').show();\n",
      "             $('div.output_area').show();\n",
      "         }\n",
      "         show = !show\n",
      "     }\n",
      " </script>\n",
      " <a id=\"toggle\" href=\"javascript:toggle()\" target=\"_self\">toggle sections</a>\"\"\")\n",
      "toggle_sections"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "\n",
        "<script type=\"text/javascript\">\n",
        "     show=true;\n",
        "     function toggle(){\n",
        "         if (show){\n",
        "             $('div.input').hide();\n",
        "             $('div.output_area').hide();\n",
        "             $(\"#toggle\").parent().parent().show()\n",
        "         }else{\n",
        "             $('div.input').show();\n",
        "             $('div.output_area').show();\n",
        "         }\n",
        "         show = !show\n",
        "     }\n",
        " </script>\n",
        " <a id=\"toggle\" href=\"javascript:toggle()\" target=\"_self\">toggle sections</a>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 180,
       "text": [
        "<IPython.core.display.HTML at 0x6e8e090>"
       ]
      }
     ],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import random, os,sys\n",
      "from hashlib import md5\n",
      "sys.path.append(os.environ['WWAH_SRC'])\n",
      "from student_behavior_analysis.cluster_exprs import cluster_expr_dataframe, preprocess_exprs, preprocessor\n",
      "from numpy.linalg import lstsq\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cluster import KMeans\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn import cross_validation\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import scipy as sp\n",
      "import pickle\n",
      "from datetime import timedelta\n",
      "import random\n",
      "import matplotlib.pyplot as plt\n",
      "from scipy.stats import pearsonr\n",
      "from webwork.expr_parser.webwork_parser import parse_webwork\n",
      "from pprint import pprint\n",
      "from collections import defaultdict\n",
      "import nltk\n",
      "\n",
      "def sample_df(df, samples):\n",
      "    ''' Samples rows of a dataframe '''\n",
      "    if len(df)<samples:\n",
      "        return df\n",
      "    else:\n",
      "        rows = random.sample(df.index, samples)\n",
      "        return df.ix[rows]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 182
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Load/Prepare Data #"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load Attempt Logs from pickle files ###\n",
      "\n",
      "The pickle files being loaded are:\n",
      "\n",
      "    UCSD_CSE103_behavioral_statistics_past_answer.pkl\n",
      "    UCSD_CSE103_behavioral_statistics_realtime.pkl\n",
      "    UCSD_CSE103_processed_assigned_hints.pkl\n",
      "    UCSD_CSE103_processed_logs_past_answer.pkl\n",
      "\n",
      "And mean:\n",
      "\n",
      "* behavioral = the *aggregate* number of tries and amount of time spent \n",
      "* processed_logs = the log of answers made by each student.\n",
      "* processed_assigned_hints = Table mapping hint id to the problem part with which it is associated.\n",
      "* past_answer/realtime = collected only when student submits, realtime is any keystroke (through the javascript)\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "course_name='UCSD_CSE103'\n",
      "\n",
      "# Load the table mapping <assigned hint id> to the problem-part-id of the hint\n",
      "assigned_hints_path = '%s/%s_processed_assigned_hints.pkl' \\\n",
      "    %(os.environ['WWAH_PICKLE'],course_name)\n",
      "with open(assigned_hints_path,'rb') as f:\n",
      "    assigned_hints = pickle.load(f).set_index('assigned_hint_id')\n",
      "\n",
      "# Load aggregate assignment/problem/part/user statistics into variable `agg`\n",
      "behavioral_statistics_path = '%s/%s_behavioral_statistics_realtime.pkl' \\\n",
      "    %(os.environ['WWAH_PICKLE'],course_name)\n",
      "with open(behavioral_statistics_path,'rb') as f:\n",
      "    agg = pickle.load(f)['BehaviourStatistics']\n",
      "\n",
      "# Load timestamped answer logs into variable `logs`\n",
      "processed_logs_path = '%s/%s_processed_logs_realtime.pkl' \\\n",
      "    %(os.environ['WWAH_PICKLE'],course_name)\n",
      "with open(processed_logs_path,'rb') as f:\n",
      "    logs = pickle.load(f)['FullRealtimeDataFrame']\n",
      "\n",
      "# Print loaded DataFrames\n",
      "#print 'Aggregate behavior statistics:'\n",
      "#print agg\n",
      "#print '\\nFull answer log:'\n",
      "#print logs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 183
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Filter a Part ###\n",
      "Choose a part among the poker hand problem sets with a large number of tries.  \n",
      "Let 'df' be a DataFrame with attempts from only that problem part.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Get the problem \n",
      "index = -15\n",
      "\n",
      "# Find a problem part with lots of tries.  This means it's probably hard, and we have a lot of data for it.  \n",
      "poker_assignments = logs[(logs['Assignment'] == 'Assignment10.14.13') | \n",
      "                         (logs['Assignment'] == 'Assignment10.16.13') | \n",
      "                         (logs['Assignment'] == 'Assignment10.18.13')]\n",
      "parts = poker_assignments.groupby(['Assignment','problem_no','part_no']).size()\n",
      "# Sort parts by number of tries\n",
      "parts.sort()\n",
      "# Choose a part from the end- with a large number of tries\n",
      "assignment, problem, part = parts.index[index]\n",
      "#assignment = 'Assignment10.18.13'; problem = 2; part = 4\n",
      "# Get a dataframe, filtered by this problem part\n",
      "df_filtered = logs[(logs['Assignment'] == assignment) & (logs['problem_no'] == problem) & (logs['part_no'] == part)]\n",
      "print '%s problem %d ***part %d*** was difficult.  Students made %d attempts total' % \\\n",
      "    (assignment, problem, part, parts[index])\n",
      "print 'Webwork problem link: '\n",
      "print 'http://webwork.cse.ucsd.edu/webwork2/UCSD_CSE103/%s/%d' % \\\n",
      "    (assignment, problem)\n",
      "    \n",
      "hints_link='http://webwork.cse.ucsd.edu/teacher/student_monitor.html?teacher_id=melkherj&student_id=melkherj&course_id=UCSD_CSE103&set_id=%s&problem_id=%d&sockjs_port=4350&rest_port=4351' \\\n",
      " % (assignment, problem)\n",
      "print 'hints link: '\n",
      "print hints_link"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Assignment10.16.13 problem 2 ***part 8*** was difficult.  Students made 1321 attempts total\n",
        "Webwork problem link: \n",
        "http://webwork.cse.ucsd.edu/webwork2/UCSD_CSE103/Assignment10.16.13/2\n",
        "hints link: \n",
        "http://webwork.cse.ucsd.edu/teacher/student_monitor.html?teacher_id=melkherj&student_id=melkherj&course_id=UCSD_CSE103&set_id=Assignment10.16.13&problem_id=2&sockjs_port=4350&rest_port=4351\n"
       ]
      }
     ],
     "prompt_number": 184
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = df_filtered.copy()\n",
      "vocab_list, vocab_hash, X = preprocess_exprs(df['answer'])\n",
      "# Syntax errors are those expressions with no features\n",
      "df['syntax_err'] = (X.sum(axis=1) == 0)\n",
      "X = X[~df['syntax_err'],:]\n",
      "df = df[~df['syntax_err']]\n",
      "# For very simple expressions, distances break down\n",
      "too_simple = (X.sum(axis=1) <= 5)\n",
      "df = df[~too_simple]\n",
      "X = X[~too_simple,:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 185
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Reduce Dimensionality #"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Random Projections ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sample_margin(X, samples, delta):\n",
      "    ''' X is an n X d matrix, giving n examples from a d-dimensional space\n",
      "        Choose <samples> examples at random.  Choose a random d-dimensional \n",
      "        vector w form the d-1 sphere.  \n",
      "        Project X onto 1-dimension using w.  \n",
      "        Return w, the offset that would give the largest margin separation in \n",
      "        the 1-D space, and the margin achieved.  \n",
      "        \n",
      "        Once examples are projected/sorted, <delta> examples are ignored at the\n",
      "        beginning at end when finding the optimal separation.  Otherwise\n",
      "        outliers would give large margin.  '''\n",
      "        \n",
      "    dim = X.shape[1]\n",
      "    X_sample = np.vstack(random.sample(X,samples))\n",
      "    w = random_vec(dim)\n",
      "    Y_sample = project(X_sample,w)\n",
      "\n",
      "    # Get max margin and offset\n",
      "    Y_sorted = np.sort(Y_sample)\n",
      "    margins = np.diff(Y_sorted)\n",
      "    # ensure that a large number of points are separated by margin\n",
      "    # --> statistical significance\n",
      "    margins[:delta] = 0\n",
      "    margins[-delta:] = 0\n",
      "    i = np.argmax(margins)\n",
      "    max_b = (Y_sorted[i+1] + Y_sorted[i])/2.0\n",
      "    max_margin = margins[i]\n",
      "    \n",
      "    return w, max_b, max_margin\n",
      "\n",
      "def random_vec(dim):\n",
      "    w = np.random.normal(size=(dim,))\n",
      "    return w / np.linalg.norm(w)\n",
      "\n",
      "def project(X,w):\n",
      "    return (X*w).sum(axis=1)\n",
      "\n",
      "def rp_reduce(X, d, method='gaussian'):\n",
      "    ''' Reduce dimensionality of X to dimension d using random projections. \n",
      "        method='gaussian' chooses the least gaussian among the projections using Shapiro-Wilks test\n",
      "        method='max_margin' chooses the projection with the largest margin\n",
      "        method='random' the random projection randomly\n",
      "        '''\n",
      "    # Try out 1000 random projections.  Record how gaussian these are\n",
      "    ps = []\n",
      "    ws = []\n",
      "    d1 = X.shape[1] #original dimension\n",
      "    for i in range(1000):\n",
      "        # Use \"non-gaussian\" to evaluate projection\n",
      "        if method=='gaussian':\n",
      "            w = random_vec(d1)\n",
      "            proj = project(X,w)\n",
      "            _,p = sp.stats.shapiro(proj)\n",
      "            ps.append(-p)\n",
      "        elif method=='max_margin':\n",
      "            w, _, max_margin = sample_margin(X, 50, 5)\n",
      "            ps.append(max_margin)\n",
      "        elif method=='random':\n",
      "            w = random_vec(d1)\n",
      "            ps.append(random.random())\n",
      "        ws.append(w)\n",
      "\n",
      "    # Calculate low-dimensional projection X_best\n",
      "    ps = np.array(ps)\n",
      "    best_projs = np.argsort(ps)[-d:] #select top d ps\n",
      "    best_ws = [ws[i] for i in best_projs]\n",
      "    W = np.vstack(best_ws) #best projections\n",
      "    X2 = np.dot(X,W.T)\n",
      "    return X2"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 194
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Select Features ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def select_features(X, d, method='informative'):\n",
      "    ''' X is an n X d binary matrix where each row gives an example in {0,1}^d\n",
      "        Return X, the d features with the greatest entropy (closest to 1/2 occurrance) \n",
      "        if method='random', pick d features randomly '''\n",
      "    if method=='informative':\n",
      "        # Define set of informative features\n",
      "        occ = X.mean(axis=0)\n",
      "        occ = np.abs(0.5 - occ) #distance from 0.5\n",
      "        features  = np.argsort(occ)[:d]\n",
      "    elif method=='random':\n",
      "        all_features = range(X.shape[1])\n",
      "        features = random.sample(all_features, d)\n",
      "    X2 = X[:,features]\n",
      "    return X[:,features] #Reduced dimensional matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 187
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### PCA ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def svd_reduce(X, d):\n",
      "    model = PCA(n_components=d)\n",
      "    return model.fit_transform(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 188
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Choose and Run Dimensionality Reduction ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "reduction_methods = ['rp_gaussian','rp_max_margin','rp_random','informative_features','random_features','pca']\n",
      "\n",
      "def dim_reduce(X, d, method):\n",
      "    ''' Select a method in <reduction_methods>\n",
      "        Reduce dimensionality of X to d '''\n",
      "    if method in ['rp_gaussian','rp_max_margin','rp_random']:\n",
      "        return rp_reduce(X, d, method=method[3:])\n",
      "    elif method=='informative_features':\n",
      "        return select_features(X, d, method='informative')\n",
      "    elif method=='random_features':\n",
      "        return select_features(X, d, method='random')\n",
      "    elif method=='pca':\n",
      "        return svd_reduce(X, d)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 189
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Classify and Evaluate Performance #\n",
      "Idea: if we can classify expressions as incorrect/correct almost as well in a low-dimensional space, \n",
      "we can use features in this low-dimensional-space to group almost-correct answers.  "
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Evaluate Dimensionality Reduction Via Correct Answer Classification ###"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cross_validate_classify(X,Y,test_size=0.3, random_state=0, model=LogisticRegression()):\n",
      "    # Given examples as rows in X, and binary labels in Y, \n",
      "    # Randomly split X/Y into train/test examples, and evaluate classification accuracy\n",
      "    # Sample models include: LogisticRegression(), MultinomialNB(), SVC(kernel='linear')\n",
      "    ''' cross-validate 70/30 train/test, return accuracy '''\n",
      "    X_train, X_test, Y_train, Y_test = cross_validation.train_test_split(X,Y, \n",
      "                                                                         test_size=test_size)\n",
      "    model.fit(X_train, Y_train)\n",
      "    Y_pred = model.predict(X_test)\n",
      "    return (Y_pred == Y_test).mean()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 190
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "n = X.shape[0]\n",
      "d = 10\n",
      "it = 30\n",
      "train_size=30 #only 10 examples are labelled\n",
      "test_size=(1-train_size/float(n))\n",
      "\n",
      "print '### dim reduction %d -> %d ###\\n\\n'%(X.shape[1], d)\n",
      "for method in reduction_methods:\n",
      "    print 'method = %s'%method\n",
      "    accs = []\n",
      "    for _ in range(it):\n",
      "        X2 = dim_reduce(X,d,method)\n",
      "        acc = cross_validate_classify(X2,df['correct'],test_size=test_size)\n",
      "        accs.append(acc)\n",
      "    print np.mean(accs)\n",
      "    print np.std(accs)/sqrt(it)\n",
      "    print ''\n",
      "    \n",
      "print 'baseline (no dim reduction):'\n",
      "for _ in range(it):\n",
      "    acc = cross_validate_classify(X,df['correct'],test_size=test_size)\n",
      "    accs.append(acc)\n",
      "print np.mean(accs)\n",
      "print np.std(accs)/sqrt(it)\n",
      "print ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "### dim reduction 148 -> 10 ###\n",
        "\n",
        "\n",
        "method = rp_gaussian\n",
        "0.720638540479"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.00416083076652\n",
        "\n",
        "method = rp_max_margin\n",
        "0.712656784493"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.00417331120678\n",
        "\n",
        "method = rp_random\n",
        "0.722881033827"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.00828538408787\n",
        "\n",
        "method = informative_features\n",
        "0.767540858989\n",
        "0.00907305587072\n",
        "\n",
        "method = random_features\n",
        "0.717255796275"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.00568005264274\n",
        "\n",
        "method = pca\n",
        "0.823489167617"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.0101001312778\n",
        "\n",
        "baseline (no dim reduction):\n",
        "0.821265678449"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.00844056313397\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 195
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Select Close-to-Correct Answers, and Group Them #"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Reduce dimensionality using PCA ###\n",
      "PCA seems to perform best for dimensionality-reduction to improve classification.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X2 = dim_reduce(X,d,'pca')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 196
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Select Examples to Give the Same Hint ###\n",
      "* Select examples that are incorrect, but close\n",
      "* Among the close-to-correct examples, select a feature in the low-dimensional-space that has negative weight.  \n",
      "    * Find examples with negative weight for this feature.  These examples are incorrect in a similar way.  "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_almost_correct(X,df,model=LogisticRegression()):\n",
      "    model.fit(X,df['correct'])\n",
      "    df['correctness'] = model.predict_log_proba(X)[:,1]\n",
      "    almost_correct = (df['correctness'] > df['correctness'].quantile(0.6)) & (~df['correct'])\n",
      "    almost_correct_indices = np.nonzero(almost_correct)[0]\n",
      "    \n",
      "    return almost_correct_indices, model.coef_"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 197
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "almost_correct, w = get_almost_correct(X2,df)\n",
      "W = X2*w #weight of feature for each example\n",
      "negs = np.argmin(W[almost_correct,:], axis=1)\n",
      "print 'Most-negative feature'\n",
      "print negs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Most-negative feature\n",
        "[4 4 5 8 8 5 2 5 4 5 4 5 5 2 4 7 0 0 2 4 7 7 5 2 2 7 7 8 4 2 4 7 0 0 2 2 4\n",
        " 7 4 4 4 4 4 2 2 2 2 2 2 2 2 2 2 0 2 5 2 4 7 2 2 2 2 5 2 2 2 2 2 2 0 0 0 0\n",
        " 0 0 0 0 7 4 7 2 2 2 2 2 2 2 2 2 2 7 5 7 1 0 4 2 4]\n"
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "need_hint = df.ix[almost_correct].ix[negs==2]\n",
      "need_hint.ix[:10][['answer','user']]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n",
        "/usr/local/lib/python2.7/dist-packages/pandas/core/config.py:570: DeprecationWarning: height has been deprecated.\n",
        "\n",
        "  warnings.warn(d.msg, DeprecationWarning)\n"
       ]
      },
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>answer</th>\n",
        "      <th>user</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>2013-10-17 14:58:01</th>\n",
        "      <td> (4!/(3!/1!))*(12!/(8!4!))</td>\n",
        "      <td> dmariano</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-17 23:24:18</th>\n",
        "      <td>            C(12,4)*C(3,1)</td>\n",
        "      <td>     a4to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 00:19:04</th>\n",
        "      <td>            C(12,4)*C(3,1)</td>\n",
        "      <td>     a4to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 02:25:08</th>\n",
        "      <td>            C(12,3)*C(4,1)</td>\n",
        "      <td>  j7kelly</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 02:25:26</th>\n",
        "      <td>            C(12,3)*C(4,1)</td>\n",
        "      <td>  j7kelly</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 03:14:53</th>\n",
        "      <td>            C(12,4)*C(3,1)</td>\n",
        "      <td>     a4to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 04:08:10</th>\n",
        "      <td>            C(12,4)*C(3,1)</td>\n",
        "      <td>     a4to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 04:18:31</th>\n",
        "      <td>            C(12,4)*C(3,1)</td>\n",
        "      <td>     a4to</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 05:20:03</th>\n",
        "      <td>           C(12,4)*C(3,1) </td>\n",
        "      <td>    altam</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>2013-10-18 05:21:52</th>\n",
        "      <td>     C(12,4)*C(3,1)*C(2,1)</td>\n",
        "      <td>   tiz012</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 199,
       "text": [
        "                                        answer      user\n",
        "2013-10-17 14:58:01  (4!/(3!/1!))*(12!/(8!4!))  dmariano\n",
        "2013-10-17 23:24:18             C(12,4)*C(3,1)      a4to\n",
        "2013-10-18 00:19:04             C(12,4)*C(3,1)      a4to\n",
        "2013-10-18 02:25:08             C(12,3)*C(4,1)   j7kelly\n",
        "2013-10-18 02:25:26             C(12,3)*C(4,1)   j7kelly\n",
        "2013-10-18 03:14:53             C(12,4)*C(3,1)      a4to\n",
        "2013-10-18 04:08:10             C(12,4)*C(3,1)      a4to\n",
        "2013-10-18 04:18:31             C(12,4)*C(3,1)      a4to\n",
        "2013-10-18 05:20:03            C(12,4)*C(3,1)      altam\n",
        "2013-10-18 05:21:52      C(12,4)*C(3,1)*C(2,1)    tiz012"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Group Subtrees By Value #"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def round_sigfigs(num, sig_figs):\n",
      "    \"\"\"Round to specified number of sigfigs.\n",
      "\n",
      "    >>> round_sigfigs(0, sig_figs=4)\n",
      "    0\n",
      "    >>> int(round_sigfigs(12345, sig_figs=2))\n",
      "    12000\n",
      "    >>> int(round_sigfigs(-12345, sig_figs=2))\n",
      "    -12000\n",
      "    >>> int(round_sigfigs(1, sig_figs=2))\n",
      "    1\n",
      "    >>> '{0:.3}'.format(round_sigfigs(3.1415, sig_figs=2))\n",
      "    '3.1'\n",
      "    >>> '{0:.3}'.format(round_sigfigs(-3.1415, sig_figs=2))\n",
      "    '-3.1'\n",
      "    >>> '{0:.5}'.format(round_sigfigs(0.00098765, sig_figs=2))\n",
      "    '0.00099'\n",
      "    >>> '{0:.6}'.format(round_sigfigs(0.00098765, sig_figs=3))\n",
      "    '0.000988'\n",
      "    \"\"\"\n",
      "    if num != 0:\n",
      "        return round(num, -int(math.floor(math.log10(abs(num))) - (sig_figs - 1)))\n",
      "    else:\n",
      "        return 0  # Can't take the log of 0\n",
      "\n",
      "\n",
      "def tree_level_value(op, values):\n",
      "    if None in values:\n",
      "        return None #failure\n",
      "    try:\n",
      "        if op == '+':\n",
      "            return sum(values)\n",
      "        elif op == '-':\n",
      "            return -1*values[0]\n",
      "        elif op == '*':\n",
      "            return prod(values)\n",
      "        elif op == '/':\n",
      "            return 1.0/values[0]\n",
      "        elif op == '!':\n",
      "            return math.factorial(round(values[0]))\n",
      "        elif op == 'C':\n",
      "            n = values[0]\n",
      "            k = values[1]\n",
      "            if k < 0 or k > n:\n",
      "                # C(n,k) isn't defined\n",
      "                return None\n",
      "            else:\n",
      "                # C(n,k)  ~   n choose k\n",
      "                return float(  sp.misc.comb(n,k)  )\n",
      "    except TypeError:\n",
      "        return None\n",
      "\n",
      "def tree_values(tree):\n",
      "    ''' Returns the set of all value/subtree pairs, where `value` is the numerical value of mathematical\n",
      "        expression defined by the subtree'''\n",
      "    try:\n",
      "        return tree_values_helper(tree)[1]\n",
      "    except:\n",
      "        return set([])\n",
      "\n",
      "def tree_values_helper(tree):\n",
      "    ''' Returns the computed value of the expression tree, set of all value/subtree pairs) '''\n",
      "    if type(tree) == tuple:\n",
      "        # Return a list that for every subtree T rooted at a child of `tree`, gives\n",
      "        #   (the value of T and the set of value(S), S for S every subtree of T)\n",
      "        values, tvs = zip(*[tree_values_helper(t) for t in tree[1:]])\n",
      "        tv = set.union(*tvs)\n",
      "        op = tree[0]\n",
      "        value = tree_level_value(op, values)\n",
      "        if not value is None:\n",
      "            value = round_sigfigs(value,5)\n",
      "        tv.add( (value, tree))\n",
      "        return value, tv\n",
      "    else:\n",
      "        return tree, set([(tree,tree)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 200
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# v_trees is a dictionary mapping value -> set of subtrees with the value\n",
      "\n",
      "all_tree_values = list(set(\n",
      "                           t for expr in df['answer'].tolist() for t in list(tree_values(parse_webwork(expr)))\n",
      "                   ))\n",
      "v_trees = defaultdict(set)\n",
      "for (v,t) in all_tree_values:\n",
      "    v_trees[v].add(t)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Find values with lots of matching subtrees\n",
      "\n",
      "common_values = sorted(v_trees.keys(),key=lambda k:len(v_trees[k]))[-10:]\n",
      "v = common_values[5]\n",
      "print 'common value: %d\\n'%v\n",
      "print 'trees with this value:\\n'\n",
      "for t in list(v_trees[v])[:10]:\n",
      "    print t"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "common value: 495\n",
        "\n",
        "trees with this value:\n",
        "\n",
        "('*', 1, ('C', 12, 4))\n",
        "('*', ('!', 12), ('/', ('*', ('!', 4), ('!', 8))))\n",
        "('*', ('!', 12), ('/', ('*', ('!', 8), ('!', 4))))\n",
        "('*', 3, ('C', 11, 3))\n",
        "('*', ('C', 4, 4), ('C', 12, 4))\n",
        "('*', ('C', 1, 1), ('C', 12, 4))\n",
        "('*', ('C', 12, 4), ('C', 1, 1))\n",
        "('*', ('!', 12), ('/', ('*', ('!', 4), ('!', ('+', 12, ('-', 4))))))\n",
        "('C', 12, 4)\n"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Next Steps #\n",
      "* Integrate values and pruning into features\n",
      "* Fix parsing for subtraction (unary vs. binary subtraction)\n",
      "* Weight down examples from the same user\n",
      "* Select the time to give student hint.  This is an interesting problem.  "
     ]
    }
   ],
   "metadata": {}
  }
 ]
}